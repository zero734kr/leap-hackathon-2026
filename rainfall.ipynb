{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b17fcc1f-d2d7-4cc8-8daf-a3b91a41ea7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  OSN_ROOT: s3://leap-pangeo-manual/hackathon-2026/\n",
      "  SCRATCH: gs://leap-scratch/renriviera\n",
      "  RAIN_OUT: gs://leap-scratch/renriviera/sfincs_soundview_preproc/forcing/rain_hrrr\n",
      "  YEAR: 2025\n",
      "  ROI (lon): -73.882 to -73.842\n",
      "  ROI (lat): 40.807 to 40.836\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import gcsfs\n",
    "import s3fs\n",
    "\n",
    "# ============================================================\n",
    "# Configuration\n",
    "# ============================================================\n",
    "\n",
    "# OSN (HRRR data source)\n",
    "OSN_ENDPOINT_URL = \"https://nyu1.osn.mghpcc.org\"\n",
    "OSN_BUCKET = \"leap-pangeo-manual\"\n",
    "HACKATHON_PREFIX = \"hackathon-2026/\"\n",
    "OSN_ROOT = f\"s3://{OSN_BUCKET}/{HACKATHON_PREFIX}\"\n",
    "\n",
    "# Output paths\n",
    "SCRATCH_BUCKET = \"gs://leap-scratch/renriviera\"\n",
    "OUT_PREFIX = f\"{SCRATCH_BUCKET}/sfincs_soundview_preproc\"\n",
    "RAIN_OUT_PREFIX = f\"{OUT_PREFIX}/forcing/rain_hrrr\"\n",
    "\n",
    "# Year to process\n",
    "YEAR = 2025\n",
    "\n",
    "# Soundview ROI (lat/lon WGS84)\n",
    "ROI_MIN_LON = -73.882\n",
    "ROI_MAX_LON = -73.842\n",
    "ROI_MIN_LAT = 40.807\n",
    "ROI_MAX_LAT = 40.836\n",
    "\n",
    "# Target CRS (UTM Zone 18N for NYC)\n",
    "TARGET_CRS = \"EPSG:26918\"\n",
    "\n",
    "# CRITICAL: FEWS time format (same as windspeed notebook!)\n",
    "FEWS_TIME_UNITS = \"minutes since 1970-01-01 00:00:00.0 +0000\"\n",
    "RAIN_NODATA = -9999.0\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  OSN_ROOT: {OSN_ROOT}\")\n",
    "print(f\"  SCRATCH: {SCRATCH_BUCKET}\")\n",
    "print(f\"  RAIN_OUT: {RAIN_OUT_PREFIX}\")\n",
    "print(f\"  YEAR: {YEAR}\")\n",
    "print(f\"  ROI (lon): {ROI_MIN_LON} to {ROI_MAX_LON}\")\n",
    "print(f\"  ROI (lat): {ROI_MIN_LAT} to {ROI_MAX_LAT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afa3f8bb-feb8-454c-96cd-916300fd4f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Connected to OSN\n",
      "HRRR available:\n",
      "['leap-pangeo-manual/hackathon-2026/hrrr/tp/hrrrtp2020.zarr', 'leap-pangeo-manual/hackathon-2026/hrrr/tp/hrrrtp2021.zarr', 'leap-pangeo-manual/hackathon-2026/hrrr/tp/hrrrtp2022.zarr', 'leap-pangeo-manual/hackathon-2026/hrrr/tp/hrrrtp2023.zarr', 'leap-pangeo-manual/hackathon-2026/hrrr/tp/hrrrtp2024.zarr']\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# OSN S3 Filesystem (anonymous)\n",
    "# ============================================================\n",
    "\n",
    "fs_osn = s3fs.S3FileSystem(\n",
    "    anon=True,\n",
    "    client_kwargs={\"endpoint_url\": OSN_ENDPOINT_URL},\n",
    ")\n",
    "\n",
    "print(\"✅ Connected to OSN\")\n",
    "print(\"HRRR available:\")\n",
    "print(fs_osn.ls(f\"{OSN_BUCKET}/{HACKATHON_PREFIX}hrrr/tp\")[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcb417d1-a5bf-46c2-a123-fbc94bc30dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Using YEAR: 2025\n",
      "TP_STORE: s3://leap-pangeo-manual/hackathon-2026/hrrr/tp/hrrrtp2025.zarr\n",
      "✅ Opened with consolidated=True\n",
      "\n",
      "--- Dataset ---\n",
      "<xarray.Dataset> Size: 61GB\n",
      "Dimensions:              (time: 8040, y: 1059, x: 1799)\n",
      "Coordinates:\n",
      "  * time                 (time) datetime64[ns] 64kB 2025-01-01 ... 2025-12-01...\n",
      "    gribfile_projection  float64 8B ...\n",
      "    latitude             (y, x) float64 15MB dask.array<chunksize=(1059, 1799), meta=np.ndarray>\n",
      "    longitude            (y, x) float64 15MB dask.array<chunksize=(1059, 1799), meta=np.ndarray>\n",
      "    step                 timedelta64[ns] 8B ...\n",
      "    surface              float64 8B ...\n",
      "    valid_time           (time) datetime64[ns] 64kB dask.array<chunksize=(24,), meta=np.ndarray>\n",
      "Dimensions without coordinates: y, x\n",
      "Data variables:\n",
      "    tp                   (time, y, x) float32 61GB dask.array<chunksize=(24, 1059, 1799), meta=np.ndarray>\n",
      "Attributes:\n",
      "    GRIB_edition:            2\n",
      "    GRIB_centre:             kwbc\n",
      "    GRIB_centreDescription:  US National Weather Service - NCEP\n",
      "    GRIB_subCentre:          0\n",
      "    Conventions:             CF-1.7\n",
      "    institution:             US National Weather Service - NCEP\n",
      "    model:                   hrrr\n",
      "    product:                 sfc\n",
      "    description:             High-Resolution Rapid Refresh - CONUS\n",
      "    search:                  APCP:surface:0-1 hour acc\n",
      "\n",
      "Variables: ['tp']\n",
      "\n",
      "Dimensions: {'time': 8040, 'y': 1059, 'x': 1799}\n",
      "\n",
      "Time range:\n",
      "  Start: 2025-01-01T00:00:00.000000000\n",
      "  End: 2025-12-01T23:00:00.000000000\n",
      "  Steps: 8040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_76/2787736960.py:23: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  print(\"\\nDimensions:\", dict(ds.dims))\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Open HRRR tp (total precipitation) for specified YEAR\n",
    "# ============================================================\n",
    "\n",
    "TP_STORE = f\"s3://{OSN_BUCKET}/{HACKATHON_PREFIX}hrrr/tp/hrrrtp{YEAR}.zarr\"\n",
    "\n",
    "print(f\"✅ Using YEAR: {YEAR}\")\n",
    "print(f\"TP_STORE: {TP_STORE}\")\n",
    "\n",
    "# Open with fsspec\n",
    "mapper = fs_osn.get_mapper(TP_STORE)\n",
    "\n",
    "try:\n",
    "    ds = xr.open_zarr(mapper, consolidated=True)\n",
    "    print(\"✅ Opened with consolidated=True\")\n",
    "except Exception:\n",
    "    ds = xr.open_zarr(mapper, consolidated=False)\n",
    "    print(\"✅ Opened with consolidated=False\")\n",
    "\n",
    "print(\"\\n--- Dataset ---\")\n",
    "print(ds)\n",
    "print(\"\\nVariables:\", list(ds.data_vars))\n",
    "print(\"\\nDimensions:\", dict(ds.dims))\n",
    "\n",
    "# Check time coverage\n",
    "if \"time\" in ds.coords:\n",
    "    print(f\"\\nTime range:\")\n",
    "    print(f\"  Start: {ds.time.values[0]}\")\n",
    "    print(f\"  End: {ds.time.values[-1]}\")\n",
    "    print(f\"  Steps: {len(ds.time)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdc29662-f7bc-4403-95f1-e89388a61d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected variable: tp\n",
      "\n",
      "Precipitation variable:\n",
      "  Dimensions: ('time', 'y', 'x')\n",
      "  Shape: (8040, 1059, 1799)\n",
      "  Dtype: float32\n",
      "\n",
      "Coordinates:\n",
      "  gribfile_projection: ()\n",
      "  latitude: (1059, 1799)\n",
      "  longitude: (1059, 1799)\n",
      "  step: ()\n",
      "  surface: ()\n",
      "  time: (8040,)\n",
      "  valid_time: (8040,)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Extract precipitation variable + standardize\n",
    "# ============================================================\n",
    "\n",
    "# Pick main variable (should be 'tp')\n",
    "def pick_main_var(ds, prefer_substrings=(\"tp\", \"precip\", \"precipitation\")):\n",
    "    if len(ds.data_vars) == 0:\n",
    "        raise RuntimeError(\"Dataset has no data variables\")\n",
    "    \n",
    "    # Prefer variables that look like precip\n",
    "    for key in ds.data_vars:\n",
    "        lk = key.lower()\n",
    "        if any(s in lk for s in prefer_substrings):\n",
    "            return key\n",
    "    return list(ds.data_vars)[0]\n",
    "\n",
    "tp_var = pick_main_var(ds)\n",
    "print(f\"Selected variable: {tp_var}\")\n",
    "\n",
    "# Extract as DataArray\n",
    "tp = ds[tp_var]\n",
    "\n",
    "print(\"\\nPrecipitation variable:\")\n",
    "print(f\"  Dimensions: {tp.dims}\")\n",
    "print(f\"  Shape: {tp.shape}\")\n",
    "print(f\"  Dtype: {tp.dtype}\")\n",
    "\n",
    "# Check coordinates\n",
    "print(f\"\\nCoordinates:\")\n",
    "for coord in tp.coords:\n",
    "    print(f\"  {coord}: {tp.coords[coord].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a17eb9a-8b9c-451a-bcb4-673812d63e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating spatial maximum...\n",
      "Exact cells in ROI: 2\n",
      "\n",
      "✅ Computing spatial maximum...\n",
      "\n",
      "Time series:\n",
      "  Length: 8040\n",
      "  Precip max: 28.50 mm/hr\n",
      "\n",
      "⚠️ Creating 2D grid for HydroMT compatibility...\n",
      "Created 2x2 grid centered at (595966, 4519565)\n",
      "  Grid spacing: 5.0 km\n",
      "✅ Tiled precip grid: (8040, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell 6 (FIXED): Calculate spatial maximum AND create 2D grid\n",
    "# ============================================================\n",
    "\n",
    "print(\"Calculating spatial maximum...\")\n",
    "\n",
    "# Get subset lat/lon\n",
    "lat_subset = tp[\"latitude\"].values\n",
    "lon_subset = tp[\"longitude\"].values\n",
    "\n",
    "if np.nanmax(lon_subset) > 180:\n",
    "    lon_subset = ((lon_subset + 180) % 360) - 180\n",
    "\n",
    "# Create precise mask\n",
    "precise_mask = (\n",
    "    (lat_subset >= ROI_MIN_LAT) & (lat_subset <= ROI_MAX_LAT) &\n",
    "    (lon_subset >= ROI_MIN_LON) & (lon_subset <= ROI_MAX_LON)\n",
    ")\n",
    "\n",
    "print(f\"Exact cells in ROI: {precise_mask.sum()}\")\n",
    "\n",
    "# Mask out non-ROI cells\n",
    "tp_masked = tp.where(precise_mask)\n",
    "\n",
    "# Calculate MAXIMUM across space at each timestep\n",
    "rain_max = tp_masked.max(dim=[\"y\", \"x\"], skipna=True)\n",
    "\n",
    "print(\"\\n✅ Computing spatial maximum...\")\n",
    "rain_values = rain_max.compute()\n",
    "\n",
    "print(f\"\\nTime series:\")\n",
    "print(f\"  Length: {len(rain_values)}\")\n",
    "print(f\"  Precip max: {rain_values.max().values:.2f} mm/hr\")\n",
    "\n",
    "# ============================================================\n",
    "# CRITICAL FIX: Create proper 2D grid for SFINCS\n",
    "# Tile the maximum value across a minimal 2x2 grid\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n⚠️ Creating 2D grid for HydroMT compatibility...\")\n",
    "\n",
    "# Get center coordinates of ROI\n",
    "lat_center = (ROI_MIN_LAT + ROI_MAX_LAT) / 2\n",
    "lon_center = (ROI_MIN_LON + ROI_MAX_LON) / 2\n",
    "\n",
    "# Transform to UTM\n",
    "from pyproj import Transformer\n",
    "transformer = Transformer.from_crs(\"EPSG:4326\", TARGET_CRS, always_xy=True)\n",
    "x_center, y_center = transformer.transform(lon_center, lat_center)\n",
    "\n",
    "# Create a small 2x2 grid around center point\n",
    "# Grid spacing ~5km (SFINCS will interpolate to model grid anyway)\n",
    "grid_spacing = 5000  # meters\n",
    "\n",
    "x_coords = np.array([x_center - grid_spacing, x_center + grid_spacing])\n",
    "y_coords = np.array([y_center - grid_spacing, y_center + grid_spacing])\n",
    "\n",
    "print(f\"Created 2x2 grid centered at ({x_center:.0f}, {y_center:.0f})\")\n",
    "print(f\"  Grid spacing: {grid_spacing/1000:.1f} km\")\n",
    "\n",
    "# Tile the maximum precip value to all grid cells\n",
    "# Shape: (time, y=2, x=2)\n",
    "rain_2d = np.tile(\n",
    "    rain_values.values[:, np.newaxis, np.newaxis],  # (time, 1, 1)\n",
    "    (1, 2, 2)  # Tile to (time, 2, 2)\n",
    ")\n",
    "\n",
    "print(f\"✅ Tiled precip grid: {rain_2d.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f4d50ea-62a7-47ff-b92a-f096f1421b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting time to FEWS format...\n",
      "\n",
      "✅ Time converted to FEWS format:\n",
      "  Units: minutes since 1970-01-01 00:00:00.0 +0000\n",
      "  Range: 28928160 to 29410500 minutes\n",
      "\n",
      "Verification:\n",
      "  First time: 2025-01-01T00:00:00\n",
      "  Last time: 2025-12-01T23:00:00\n",
      "✅ Time conversion verified\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Convert time to FEWS format (unchanged)\n",
    "# ============================================================\n",
    "\n",
    "print(\"Converting time to FEWS format...\")\n",
    "\n",
    "t0 = np.datetime64(\"1970-01-01T00:00:00\")\n",
    "t_minutes = ((rain_values[\"time\"].values - t0) / np.timedelta64(1, \"m\")).astype(\"int64\")\n",
    "\n",
    "print(f\"\\n✅ Time converted to FEWS format:\")\n",
    "print(f\"  Units: {FEWS_TIME_UNITS}\")\n",
    "print(f\"  Range: {t_minutes.min()} to {t_minutes.max()} minutes\")\n",
    "\n",
    "# Verify\n",
    "first_datetime = np.datetime64(\"1970-01-01T00:00:00\") + np.timedelta64(int(t_minutes[0]), \"m\")\n",
    "last_datetime = np.datetime64(\"1970-01-01T00:00:00\") + np.timedelta64(int(t_minutes[-1]), \"m\")\n",
    "\n",
    "print(f\"\\nVerification:\")\n",
    "print(f\"  First time: {first_datetime}\")\n",
    "print(f\"  Last time: {last_datetime}\")\n",
    "\n",
    "if first_datetime.astype('datetime64[Y]').astype(int) + 1970 != YEAR:\n",
    "    raise ValueError(f\"Time conversion error! First time is not in {YEAR}\")\n",
    "\n",
    "print(\"✅ Time conversion verified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b40db84c-63be-41f1-9010-f0e43b7ec64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building FEWS precipitation dataset...\n",
      "\n",
      "✅ FEWS dataset built:\n",
      "<xarray.Dataset> Size: 193kB\n",
      "Dimensions:  (time: 8040, y: 2, x: 2)\n",
      "Coordinates:\n",
      "  * time     (time) int64 64kB 28928160 28928220 28928280 ... 29410440 29410500\n",
      "  * y        (y) float64 16B 4.515e+06 4.525e+06\n",
      "  * x        (x) float64 16B 5.91e+05 6.01e+05\n",
      "Data variables:\n",
      "    precip   (time, y, x) float32 129kB 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0\n",
      "Attributes:\n",
      "    crs:      EPSG:26918\n",
      "\n",
      "Dimensions: {'time': 8040, 'y': 2, 'x': 2}\n",
      "Spatial grid: 2 x 2\n",
      "✅ Grid validation passed (2x2 minimum)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Build FEWS-format NetCDF with proper 2D spatial grid\n",
    "# ============================================================\n",
    "\n",
    "print(\"Building FEWS precipitation dataset...\")\n",
    "\n",
    "# Ensure float32 and replace NaN\n",
    "rain_2d = np.where(np.isfinite(rain_2d), rain_2d, RAIN_NODATA).astype(\"float32\")\n",
    "\n",
    "# Build xarray Dataset with proper 2D grid\n",
    "rain_fews = xr.Dataset(\n",
    "    data_vars={\n",
    "        \"precip\": ((\"time\", \"y\", \"x\"), rain_2d),\n",
    "    },\n",
    "    coords={\n",
    "        \"time\": (\"time\", t_minutes),\n",
    "        \"x\": (\"x\", x_coords),\n",
    "        \"y\": (\"y\", y_coords),\n",
    "    },\n",
    ")\n",
    "\n",
    "# Set attributes\n",
    "rain_fews[\"time\"].attrs[\"units\"] = FEWS_TIME_UNITS\n",
    "rain_fews[\"precip\"].attrs.update({\n",
    "    \"long_name\": \"precipitation\",\n",
    "    \"units\": \"mm/hr\",\n",
    "    \"description\": \"Spatially-uniform hourly precipitation from HRRR (max across ROI)\"\n",
    "})\n",
    "rain_fews.attrs[\"crs\"] = TARGET_CRS\n",
    "\n",
    "print(\"\\n✅ FEWS dataset built:\")\n",
    "print(rain_fews)\n",
    "print(f\"\\nDimensions: {dict(rain_fews.sizes)}\")\n",
    "print(f\"Spatial grid: {len(rain_fews.y)} x {len(rain_fews.x)}\")\n",
    "\n",
    "# Verify it's a proper 2D grid\n",
    "if rain_fews.sizes[\"y\"] < 2 or rain_fews.sizes[\"x\"] < 2:\n",
    "    raise ValueError(\n",
    "        f\"Grid too small! Need at least 2x2, got {rain_fews.sizes['y']}x{rain_fews.sizes['x']}\"\n",
    "    )\n",
    "\n",
    "print(\"✅ Grid validation passed (2x2 minimum)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d615d512-f590-448c-b3d1-c6c5519eaf81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing NetCDF locally...\n",
      "✅ Local NetCDF written: /tmp/sfincs_rain_fews_yggwg_vm/sfincs_rain_hrrr_soundview_2025.nc\n",
      "  Size: 0.08 MB\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Write FEWS NetCDF to local temp file\n",
    "# ============================================================\n",
    "\n",
    "import tempfile\n",
    "\n",
    "print(\"Writing NetCDF locally...\")\n",
    "\n",
    "local_dir = Path(tempfile.mkdtemp(prefix=\"sfincs_rain_fews_\"))\n",
    "out_local = local_dir / \"sfincs_rain_hrrr_soundview_2025.nc\"\n",
    "\n",
    "# Remove _FillValue from attrs (goes in encoding)\n",
    "if \"_FillValue\" in rain_fews[\"precip\"].attrs:\n",
    "    rain_fews[\"precip\"].attrs.pop(\"_FillValue\")\n",
    "\n",
    "# NetCDF encoding\n",
    "encoding = {\n",
    "    \"precip\": {\n",
    "        \"dtype\": \"float32\",\n",
    "        \"zlib\": True,\n",
    "        \"complevel\": 4,\n",
    "        \"_FillValue\": RAIN_NODATA,\n",
    "    },\n",
    "}\n",
    "\n",
    "rain_fews.to_netcdf(out_local, encoding=encoding)\n",
    "\n",
    "print(f\"✅ Local NetCDF written: {out_local}\")\n",
    "print(f\"  Size: {out_local.stat().st_size / (1024*1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "637d8e43-b3d9-4ccb-b412-955a6e4d99db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading to GCS...\n",
      "Target: gs://leap-scratch/renriviera/sfincs_soundview_preproc/forcing/rain_hrrr/sfincs_rain_hrrr_soundview_2025.nc\n",
      "✅ Uploaded to GCS\n",
      "\n",
      "Validation:\n",
      "  Exists: True\n",
      "  Size: 0.08 MB\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Upload to GCS Scratch\n",
    "# ============================================================\n",
    "\n",
    "print(\"Uploading to GCS...\")\n",
    "\n",
    "fs_gcs = gcsfs.GCSFileSystem()\n",
    "\n",
    "out_gcs = f\"{RAIN_OUT_PREFIX}/sfincs_rain_hrrr_soundview_{YEAR}.nc\"\n",
    "\n",
    "# Remove gs:// prefix for gcsfs\n",
    "gcs_path_no_scheme = out_gcs.replace(\"gs://\", \"\")\n",
    "\n",
    "print(f\"Target: {out_gcs}\")\n",
    "\n",
    "fs_gcs.put(str(out_local), gcs_path_no_scheme)\n",
    "\n",
    "print(\"✅ Uploaded to GCS\")\n",
    "print(f\"\\nValidation:\")\n",
    "print(f\"  Exists: {fs_gcs.exists(gcs_path_no_scheme)}\")\n",
    "\n",
    "if fs_gcs.exists(gcs_path_no_scheme):\n",
    "    size_mb = fs_gcs.size(gcs_path_no_scheme) / (1024*1024)\n",
    "    print(f\"  Size: {size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0db8716-2dba-405d-8a8d-89cbb618f6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VALIDATION\n",
      "============================================================\n",
      "⚠️ Remote open failed, downloading for validation\n",
      "\n",
      "Dataset:\n",
      "<xarray.Dataset> Size: 193kB\n",
      "Dimensions:  (time: 8040, y: 2, x: 2)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 64kB 2025-01-01 ... 2025-12-01T23:00:00\n",
      "  * y        (y) float64 16B 4.515e+06 4.525e+06\n",
      "  * x        (x) float64 16B 5.91e+05 6.01e+05\n",
      "Data variables:\n",
      "    precip   (time, y, x) float32 129kB ...\n",
      "Attributes:\n",
      "    crs:      EPSG:26918\n",
      "✅ Required variables present\n",
      "✅ Dimensions correct: (time, y, x)\n",
      "✅ Time is datetime64 and monotonic\n",
      "✅ Spatial coordinates valid\n",
      "✅ No NaNs in data\n",
      "\n",
      "Data range check:\n",
      "  p99: 1.24 mm/hr\n",
      "  ✅ Values in reasonable range\n",
      "✅ CRS attribute: EPSG:26918\n",
      "\n",
      "============================================================\n",
      "VALIDATION COMPLETE\n",
      "============================================================\n",
      "\n",
      "✅ Rain forcing file ready:\n",
      "   gs://leap-scratch/renriviera/sfincs_soundview_preproc/forcing/rain_hrrr/sfincs_rain_hrrr_soundview_2025.nc\n",
      "\n",
      "✅ Compatible with HydroMT-SFINCS FEWS format\n",
      "   - Time: minutes since 1970-01-01 00:00:00.0 +0000\n",
      "   - Variable: precip (mm/hr)\n",
      "   - Dimensions: (time=8040, y=2, x=2)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Validate uploaded file matches FEWS requirements\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"VALIDATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Reopen from GCS\n",
    "try:\n",
    "    ds_check = xr.open_dataset(out_gcs, engine=\"netcdf4\")\n",
    "    print(\"✅ Opened from GCS with netcdf4\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Remote open failed, downloading for validation\")\n",
    "    import tempfile\n",
    "    local_check = Path(tempfile.mkdtemp()) / \"check.nc\"\n",
    "    fs_gcs.get(gcs_path_no_scheme, str(local_check))\n",
    "    ds_check = xr.open_dataset(local_check)\n",
    "\n",
    "print(\"\\nDataset:\")\n",
    "print(ds_check)\n",
    "\n",
    "# Required checks\n",
    "REQUIRED_VARS = [\"precip\"]\n",
    "REQUIRED_DIMS = (\"time\", \"y\", \"x\")\n",
    "\n",
    "# 1. Variables\n",
    "missing = [v for v in REQUIRED_VARS if v not in ds_check.data_vars]\n",
    "if missing:\n",
    "    raise AssertionError(f\"❌ Missing variables: {missing}\")\n",
    "print(\"✅ Required variables present\")\n",
    "\n",
    "# 2. Dimensions\n",
    "for v in REQUIRED_VARS:\n",
    "    if tuple(ds_check[v].dims) != REQUIRED_DIMS:\n",
    "        raise AssertionError(f\"❌ {v} dims {ds_check[v].dims} != {REQUIRED_DIMS}\")\n",
    "print(\"✅ Dimensions correct: (time, y, x)\")\n",
    "\n",
    "# 3. Time format\n",
    "if \"time\" not in ds_check.coords:\n",
    "    raise AssertionError(\"❌ Missing time coordinate\")\n",
    "\n",
    "if not np.issubdtype(ds_check[\"time\"].dtype, np.datetime64):\n",
    "    raise AssertionError(f\"❌ time dtype should be datetime64, got {ds_check['time'].dtype}\")\n",
    "\n",
    "# Check time is monotonic\n",
    "t_vals = ds_check[\"time\"].values\n",
    "t_diffs = np.diff(t_vals.astype(\"datetime64[s]\"))\n",
    "if not np.all(t_diffs > np.timedelta64(0, \"s\")):\n",
    "    raise AssertionError(\"❌ time not monotonic\")\n",
    "print(\"✅ Time is datetime64 and monotonic\")\n",
    "\n",
    "# 4. Spatial coords\n",
    "for coord in [\"x\", \"y\"]:\n",
    "    if coord not in ds_check.coords:\n",
    "        raise AssertionError(f\"❌ Missing {coord}\")\n",
    "    if ds_check[coord].ndim != 1:\n",
    "        raise AssertionError(f\"❌ {coord} must be 1D\")\n",
    "print(\"✅ Spatial coordinates valid\")\n",
    "\n",
    "# 5. Data validity\n",
    "sample = ds_check[\"precip\"].isel(time=slice(0, min(100, len(ds_check.time)))).values\n",
    "if np.isnan(sample).any():\n",
    "    raise AssertionError(\"❌ Contains NaNs (should be filled)\")\n",
    "print(\"✅ No NaNs in data\")\n",
    "\n",
    "# 6. Value ranges\n",
    "valid_data = sample[sample != RAIN_NODATA]\n",
    "if valid_data.size > 0:\n",
    "    p99 = float(np.quantile(valid_data, 0.99))\n",
    "    print(f\"\\nData range check:\")\n",
    "    print(f\"  p99: {p99:.2f} mm/hr\")\n",
    "    if p99 > 500:\n",
    "        print(f\"  ⚠️ Very high precipitation (>{p99:.1f} mm/hr)\")\n",
    "    else:\n",
    "        print(f\"  ✅ Values in reasonable range\")\n",
    "\n",
    "# 7. CRS attribute\n",
    "crs_attr = ds_check.attrs.get(\"crs\", None)\n",
    "if crs_attr:\n",
    "    print(f\"✅ CRS attribute: {crs_attr}\")\n",
    "else:\n",
    "    print(\"⚠️ CRS attribute missing (not fatal)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VALIDATION COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n✅ Rain forcing file ready:\")\n",
    "print(f\"   {out_gcs}\")\n",
    "print(f\"\\n✅ Compatible with HydroMT-SFINCS FEWS format\")\n",
    "print(f\"   - Time: {FEWS_TIME_UNITS}\")\n",
    "print(f\"   - Variable: precip (mm/hr)\")\n",
    "print(f\"   - Dimensions: (time={len(ds_check.time)}, y={len(ds_check.y)}, x={len(ds_check.x)})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
