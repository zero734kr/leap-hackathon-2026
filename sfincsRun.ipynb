{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "41b66a8a-7658-4efe-8b75-e481571b9aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hydromt_sfincs in /srv/conda/envs/notebook/lib/python3.12/site-packages (1.2.2)\n",
      "Requirement already satisfied: affine in /srv/conda/envs/notebook/lib/python3.12/site-packages (from hydromt_sfincs) (2.4.0)\n",
      "Requirement already satisfied: geopandas>1.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from hydromt_sfincs) (1.1.1)\n",
      "Requirement already satisfied: hydromt<1.0,>=0.10.1 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from hydromt_sfincs) (0.10.1)\n",
      "Requirement already satisfied: numba in /srv/conda/envs/notebook/lib/python3.12/site-packages (from hydromt_sfincs) (0.62.1)\n",
      "Requirement already satisfied: numpy in /srv/conda/envs/notebook/lib/python3.12/site-packages (from hydromt_sfincs) (2.3.4)\n",
      "Requirement already satisfied: pandas in /srv/conda/envs/notebook/lib/python3.12/site-packages (from hydromt_sfincs) (2.3.3)\n",
      "Requirement already satisfied: pillow in /srv/conda/envs/notebook/lib/python3.12/site-packages (from hydromt_sfincs) (12.0.0)\n",
      "Requirement already satisfied: pyflwdir>=0.5.10 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from hydromt_sfincs) (0.5.10)\n",
      "Requirement already satisfied: pyproj in /srv/conda/envs/notebook/lib/python3.12/site-packages (from hydromt_sfincs) (3.7.2)\n",
      "Requirement already satisfied: rasterio in /srv/conda/envs/notebook/lib/python3.12/site-packages (from hydromt_sfincs) (1.4.3)\n",
      "Requirement already satisfied: scipy in /srv/conda/envs/notebook/lib/python3.12/site-packages (from hydromt_sfincs) (1.16.3)\n",
      "Requirement already satisfied: shapely in /srv/conda/envs/notebook/lib/python3.12/site-packages (from hydromt_sfincs) (2.1.2)\n",
      "Requirement already satisfied: xarray in /srv/conda/envs/notebook/lib/python3.12/site-packages (from hydromt_sfincs) (2025.10.1)\n",
      "Requirement already satisfied: xugrid<1.0,>=0.14 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from hydromt_sfincs) (0.14.3)\n",
      "Requirement already satisfied: bottleneck in /srv/conda/envs/notebook/lib/python3.12/site-packages (from hydromt<1.0,>=0.10.1->hydromt_sfincs) (1.6.0)\n",
      "Requirement already satisfied: click in /srv/conda/envs/notebook/lib/python3.12/site-packages (from hydromt<1.0,>=0.10.1->hydromt_sfincs) (8.3.0)\n",
      "Requirement already satisfied: dask in /srv/conda/envs/notebook/lib/python3.12/site-packages (from hydromt<1.0,>=0.10.1->hydromt_sfincs) (2025.7.0)\n",
      "Requirement already satisfied: fsspec in /srv/conda/envs/notebook/lib/python3.12/site-packages (from hydromt<1.0,>=0.10.1->hydromt_sfincs) (2025.10.0)\n",
      "Requirement already satisfied: importlib_metadata in /srv/conda/envs/notebook/lib/python3.12/site-packages (from hydromt<1.0,>=0.10.1->hydromt_sfincs) (8.7.0)\n",
      "Requirement already satisfied: mercantile in /srv/conda/envs/notebook/lib/python3.12/site-packages (from hydromt<1.0,>=0.10.1->hydromt_sfincs) (1.2.1)\n",
      "Requirement already satisfied: netcdf4 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from hydromt<1.0,>=0.10.1->hydromt_sfincs) (1.7.3)\n",
      "Requirement already satisfied: packaging in /srv/conda/envs/notebook/lib/python3.12/site-packages (from hydromt<1.0,>=0.10.1->hydromt_sfincs) (25.0)\n",
      "Requirement already satisfied: pooch in /srv/conda/envs/notebook/lib/python3.12/site-packages (from hydromt<1.0,>=0.10.1->hydromt_sfincs) (1.8.2)\n",
      "Requirement already satisfied: pydantic~=2.4 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from hydromt<1.0,>=0.10.1->hydromt_sfincs) (2.12.4)\n",
      "Requirement already satisfied: pyogrio>=0.6 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from hydromt<1.0,>=0.10.1->hydromt_sfincs) (0.11.0)\n",
      "Requirement already satisfied: pystac in /srv/conda/envs/notebook/lib/python3.12/site-packages (from hydromt<1.0,>=0.10.1->hydromt_sfincs) (1.14.1)\n",
      "Requirement already satisfied: pyyaml in /srv/conda/envs/notebook/lib/python3.12/site-packages (from hydromt<1.0,>=0.10.1->hydromt_sfincs) (6.0.3)\n",
      "Requirement already satisfied: requests in /srv/conda/envs/notebook/lib/python3.12/site-packages (from hydromt<1.0,>=0.10.1->hydromt_sfincs) (2.32.5)\n",
      "Requirement already satisfied: rioxarray in /srv/conda/envs/notebook/lib/python3.12/site-packages (from hydromt<1.0,>=0.10.1->hydromt_sfincs) (0.20.0)\n",
      "Requirement already satisfied: tomli in /srv/conda/envs/notebook/lib/python3.12/site-packages (from hydromt<1.0,>=0.10.1->hydromt_sfincs) (2.3.0)\n",
      "Requirement already satisfied: tomli-w in /srv/conda/envs/notebook/lib/python3.12/site-packages (from hydromt<1.0,>=0.10.1->hydromt_sfincs) (1.2.0)\n",
      "Requirement already satisfied: universal_pathlib>=0.2 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from hydromt<1.0,>=0.10.1->hydromt_sfincs) (0.3.8)\n",
      "Requirement already satisfied: xmltodict in /srv/conda/envs/notebook/lib/python3.12/site-packages (from hydromt<1.0,>=0.10.1->hydromt_sfincs) (1.0.2)\n",
      "Requirement already satisfied: zarr in /srv/conda/envs/notebook/lib/python3.12/site-packages (from hydromt<1.0,>=0.10.1->hydromt_sfincs) (3.1.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pydantic~=2.4->hydromt<1.0,>=0.10.1->hydromt_sfincs) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pydantic~=2.4->hydromt<1.0,>=0.10.1->hydromt_sfincs) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pydantic~=2.4->hydromt<1.0,>=0.10.1->hydromt_sfincs) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pydantic~=2.4->hydromt<1.0,>=0.10.1->hydromt_sfincs) (0.4.2)\n",
      "Requirement already satisfied: numba-celltree>=0.4.1 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from xugrid<1.0,>=0.14->hydromt_sfincs) (0.4.1)\n",
      "Requirement already satisfied: cloudpickle>=3.0.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from dask->hydromt<1.0,>=0.10.1->hydromt_sfincs) (3.1.2)\n",
      "Requirement already satisfied: partd>=1.4.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from dask->hydromt<1.0,>=0.10.1->hydromt_sfincs) (1.4.2)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from dask->hydromt<1.0,>=0.10.1->hydromt_sfincs) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pandas->hydromt_sfincs) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pandas->hydromt_sfincs) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pandas->hydromt_sfincs) (2025.2)\n",
      "Requirement already satisfied: locket in /srv/conda/envs/notebook/lib/python3.12/site-packages (from partd>=1.4.0->dask->hydromt<1.0,>=0.10.1->hydromt_sfincs) (1.0.0)\n",
      "Requirement already satisfied: llvmlite<0.46,>=0.45.0dev0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from numba->hydromt_sfincs) (0.45.1)\n",
      "Requirement already satisfied: certifi in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pyogrio>=0.6->hydromt<1.0,>=0.10.1->hydromt_sfincs) (2025.10.5)\n",
      "Requirement already satisfied: six>=1.5 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->hydromt_sfincs) (1.17.0)\n",
      "Requirement already satisfied: pathlib-abc<0.6.0,>=0.5.1 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from universal_pathlib>=0.2->hydromt<1.0,>=0.10.1->hydromt_sfincs) (0.5.2)\n",
      "Requirement already satisfied: zipp>=3.20 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from importlib_metadata->hydromt<1.0,>=0.10.1->hydromt_sfincs) (3.23.0)\n",
      "Requirement already satisfied: cftime in /srv/conda/envs/notebook/lib/python3.12/site-packages (from netcdf4->hydromt<1.0,>=0.10.1->hydromt_sfincs) (1.6.4)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pooch->hydromt<1.0,>=0.10.1->hydromt_sfincs) (4.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from requests->hydromt<1.0,>=0.10.1->hydromt_sfincs) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from requests->hydromt<1.0,>=0.10.1->hydromt_sfincs) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from requests->hydromt<1.0,>=0.10.1->hydromt_sfincs) (1.26.20)\n",
      "Requirement already satisfied: attrs in /srv/conda/envs/notebook/lib/python3.12/site-packages (from rasterio->hydromt_sfincs) (25.4.0)\n",
      "Requirement already satisfied: cligj>=0.5 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from rasterio->hydromt_sfincs) (0.7.2)\n",
      "Requirement already satisfied: click-plugins in /srv/conda/envs/notebook/lib/python3.12/site-packages (from rasterio->hydromt_sfincs) (1.1.1.2)\n",
      "Requirement already satisfied: pyparsing in /srv/conda/envs/notebook/lib/python3.12/site-packages (from rasterio->hydromt_sfincs) (3.2.5)\n",
      "Requirement already satisfied: donfig>=0.8 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from zarr->hydromt<1.0,>=0.10.1->hydromt_sfincs) (0.8.1.post1)\n",
      "Requirement already satisfied: numcodecs>=0.14 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from numcodecs[crc32c]>=0.14->zarr->hydromt<1.0,>=0.10.1->hydromt_sfincs) (0.16.1)\n",
      "Requirement already satisfied: crc32c>=2.7 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from numcodecs[crc32c]>=0.14->zarr->hydromt<1.0,>=0.10.1->hydromt_sfincs) (2.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "%pip install hydromt_sfincs\n",
    "import hydromt_sfincs\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import gcsfs\n",
    "\n",
    "from hydromt_sfincs import SfincsModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f67f14ff-4787-41a9-a478-50b8dbd316e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUT_PREFIX: gs://leap-scratch/renriviera/sfincs_soundview_preproc\n",
      "DEM: gs://leap-scratch/renriviera/sfincs_soundview_preproc/rasters/final/dep_dem_utm25m_meters.tif\n",
      "Wind: gs://leap-scratch/renriviera/sfincs_soundview_preproc/forcing/wind/sfincs_netamuamv_hrrr_u10v10_soundview_2025.nc\n",
      "Precip: gs://leap-scratch/renriviera/sfincs_soundview_preproc/forcing/sfincs.precip\n"
     ]
    }
   ],
   "source": [
    "SCRATCH_BUCKET = os.environ.get(\"SCRATCH_BUCKET\", \"gs://leap-scratch/renriviera\")\n",
    "OUT_PREFIX = f\"{SCRATCH_BUCKET.rstrip('/')}/sfincs_soundview_preproc\"\n",
    "\n",
    "# ---- Raster inputs (FINAL/CLEAN as you wrote) ----\n",
    "PATHS_GCS = {\n",
    "    \"dep_dem\":      f\"{OUT_PREFIX}/rasters/final/dep_dem_utm25m_meters.tif\",\n",
    "    \"landcover\":    f\"{OUT_PREFIX}/rasters/clean/landcover_worldcover_utm25m.tif\",\n",
    "    \"manning\":      f\"{OUT_PREFIX}/rasters/final/manning_n_utm25m.tif\",\n",
    "    \"impervious\":   f\"{OUT_PREFIX}/rasters/final/impervious_frac_utm25m.tif\",\n",
    "    \"curve_number\": f\"{OUT_PREFIX}/rasters/final/curve_number_cn_utm25m.tif\",\n",
    "}\n",
    "\n",
    "# ---- Wind forcing (your FEWS netamu/amv file) ----\n",
    "WIND_GCS = f\"{OUT_PREFIX}/forcing/wind/sfincs_netamuamv_hrrr_u10v10_soundview_2025.nc\"\n",
    "\n",
    "# ---- Precip forcing (teammate assembled) ----\n",
    "# you said: gcs_path = f\"{OUT_PREFIX}/forcing/sfincs.precip\"\n",
    "PRECIP_GCS = f\"{OUT_PREFIX}/forcing/sfincs.precip\"\n",
    "\n",
    "print(\"OUT_PREFIX:\", OUT_PREFIX)\n",
    "print(\"DEM:\", PATHS_GCS[\"dep_dem\"])\n",
    "print(\"Wind:\", WIND_GCS)\n",
    "print(\"Precip:\", PRECIP_GCS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "63597ad8-0f92-49ac-b7f9-7e45acd9c2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local input cache: /tmp/sfincs_run_inputs_7ad7mvm6\n",
      "✅ gcsfs authenticated with token='google_default'\n",
      "\n",
      "--- Download rasters locally ---\n",
      "dep_dem      exists=True -> gs://leap-scratch/renriviera/sfincs_soundview_preproc/rasters/final/dep_dem_utm25m_meters.tif\n",
      "✅ dep_dem      -> /tmp/sfincs_run_inputs_7ad7mvm6/dep_dem_utm25m_meters.tif\n",
      "landcover    exists=True -> gs://leap-scratch/renriviera/sfincs_soundview_preproc/rasters/clean/landcover_worldcover_utm25m.tif\n",
      "✅ landcover    -> /tmp/sfincs_run_inputs_7ad7mvm6/landcover_worldcover_utm25m.tif\n",
      "manning      exists=True -> gs://leap-scratch/renriviera/sfincs_soundview_preproc/rasters/final/manning_n_utm25m.tif\n",
      "✅ manning      -> /tmp/sfincs_run_inputs_7ad7mvm6/manning_n_utm25m.tif\n",
      "impervious   exists=True -> gs://leap-scratch/renriviera/sfincs_soundview_preproc/rasters/final/impervious_frac_utm25m.tif\n",
      "✅ impervious   -> /tmp/sfincs_run_inputs_7ad7mvm6/impervious_frac_utm25m.tif\n",
      "curve_number exists=True -> gs://leap-scratch/renriviera/sfincs_soundview_preproc/rasters/final/curve_number_cn_utm25m.tif\n",
      "✅ curve_number -> /tmp/sfincs_run_inputs_7ad7mvm6/curve_number_cn_utm25m.tif\n",
      "\n",
      "--- Download wind forcing locally ---\n",
      "wind exists= True -> gs://leap-scratch/renriviera/sfincs_soundview_preproc/forcing/wind/sfincs_netamuamv_hrrr_u10v10_soundview_2025.nc\n",
      "✅ wind -> /tmp/sfincs_run_inputs_7ad7mvm6/netamuamvfile.nc\n",
      "\n",
      "--- Download precip locally ---\n",
      "✅ precip file -> /tmp/sfincs_run_inputs_7ad7mvm6/sfincs_precip\n",
      "\n",
      "✅ All inputs cached locally in: /tmp/sfincs_run_inputs_7ad7mvm6\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 3) Download model inputs locally (AUTHENTICATED gcsfs)\n",
    "#    Fixes: 401 Anonymous caller error on gs://leap-scratch/*\n",
    "# ============================================================\n",
    "\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "import gcsfs\n",
    "\n",
    "cache_dir = Path(tempfile.mkdtemp(prefix=\"sfincs_run_inputs_\"))\n",
    "print(\"Local input cache:\", cache_dir)\n",
    "\n",
    "def make_gcsfs():\n",
    "    # Try authenticated modes first\n",
    "    for tok in [\"google_default\", \"cloud\"]:\n",
    "        try:\n",
    "            fs = gcsfs.GCSFileSystem(token=tok)\n",
    "            # tiny call to validate auth works\n",
    "            _ = fs.ls(\"leap-scratch/renriviera\", detail=False)[:3]\n",
    "            print(f\"✅ gcsfs authenticated with token='{tok}'\")\n",
    "            return fs\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ token='{tok}' failed:\", repr(e))\n",
    "\n",
    "    # LAST resort: anonymous (will fail for private buckets)\n",
    "    fs = gcsfs.GCSFileSystem(token=\"anon\")\n",
    "    print(\"⚠️ Falling back to anonymous gcsfs (will not work on leap-scratch)\")\n",
    "    return fs\n",
    "\n",
    "fs_gcs = make_gcsfs()\n",
    "\n",
    "def strip_gs(path: str) -> str:\n",
    "    if path.startswith(\"gs://\"):\n",
    "        return path[len(\"gs://\"):]\n",
    "    return path\n",
    "\n",
    "def gcs_exists(gs_path: str) -> bool:\n",
    "    return fs_gcs.exists(strip_gs(gs_path))\n",
    "\n",
    "def gcs_to_local(gs_path: str, local_path: Path, recursive: bool = False):\n",
    "    g = strip_gs(gs_path)\n",
    "    local_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if not fs_gcs.exists(g):\n",
    "        raise FileNotFoundError(f\"GCS path does not exist or not accessible: {gs_path}\")\n",
    "\n",
    "    # If \"recursive\" OR it's a prefix/folder-like dataset, download recursively\n",
    "    fs_gcs.get(g, str(local_path), recursive=recursive)\n",
    "\n",
    "    if not local_path.exists():\n",
    "        raise FileNotFoundError(f\"Download failed: {gs_path} -> {local_path}\")\n",
    "\n",
    "    return local_path\n",
    "\n",
    "# ---- Download rasters ----\n",
    "paths_local = {}\n",
    "print(\"\\n--- Download rasters locally ---\")\n",
    "for k, p in PATHS_GCS.items():\n",
    "    out = cache_dir / Path(p).name\n",
    "    print(f\"{k:12s} exists={gcs_exists(p)} -> {p}\")\n",
    "    paths_local[k] = gcs_to_local(p, out, recursive=False)\n",
    "    print(f\"✅ {k:12s} -> {paths_local[k]}\")\n",
    "\n",
    "# ---- Download wind netcdf ----\n",
    "print(\"\\n--- Download wind forcing locally ---\")\n",
    "print(\"wind exists=\", gcs_exists(WIND_GCS), \"->\", WIND_GCS)\n",
    "wind_local = gcs_to_local(WIND_GCS, cache_dir / \"netamuamvfile.nc\", recursive=False)\n",
    "print(\"✅ wind ->\", wind_local)\n",
    "\n",
    "# ---- Download precip (file OR folder) ----\n",
    "print(\"\\n--- Download precip locally ---\")\n",
    "precip_local = cache_dir / \"sfincs_precip\"\n",
    "precip_path_clean = strip_gs(PRECIP_GCS)\n",
    "\n",
    "if fs_gcs.exists(precip_path_clean):\n",
    "    # Try file download first\n",
    "    try:\n",
    "        precip_local_file = cache_dir / \"sfincs_precip\"\n",
    "        fs_gcs.get(precip_path_clean, str(precip_local_file), recursive=False)\n",
    "        if precip_local_file.exists():\n",
    "            precip_local = precip_local_file\n",
    "            print(\"✅ precip file ->\", precip_local)\n",
    "        else:\n",
    "            raise RuntimeError(\"Precip file download returned nothing.\")\n",
    "    except Exception as e:\n",
    "        print(\"⚠️ precip is likely a folder/prefix, switching to recursive download:\", repr(e))\n",
    "        precip_local.mkdir(parents=True, exist_ok=True)\n",
    "        fs_gcs.get(precip_path_clean, str(precip_local), recursive=True)\n",
    "        print(\"✅ precip folder ->\", precip_local)\n",
    "else:\n",
    "    raise FileNotFoundError(f\"❌ Precip path not found or not accessible: {PRECIP_GCS}\")\n",
    "\n",
    "print(\"\\n✅ All inputs cached locally in:\", cache_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e3d12bec-0889-42d3-9050-b6c082841def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local model workdir: /tmp/hydromt_sfincs_soundview_ih362uoo\n",
      "Scratch OUT_PREFIX: gs://leap-scratch/renriviera/sfincs_soundview_preproc\n",
      "✅ SfincsModel initialized\n",
      "m.root: /tmp/hydromt_sfincs_soundview_ih362uoo\n",
      "Has m.geoms?  True\n",
      "Has m.grid?   True\n",
      "Has m.config? True\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 3.5) Initialize HydroMT-SFINCS model object (m)  ✅ robust\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import tempfile\n",
    "\n",
    "from hydromt_sfincs import SfincsModel\n",
    "\n",
    "# Local run folder where HydroMT will write SFINCS input/output files\n",
    "workdir = Path(tempfile.mkdtemp(prefix=\"hydromt_sfincs_soundview_\"))\n",
    "print(\"Local model workdir:\", workdir)\n",
    "\n",
    "# Optional: scratch prefix (used later when saving results)\n",
    "SCRATCH_BUCKET = os.environ.get(\"SCRATCH_BUCKET\", \"gs://leap-scratch/renriviera\")\n",
    "OUT_PREFIX = f\"{SCRATCH_BUCKET.rstrip('/')}/sfincs_soundview_preproc\"\n",
    "print(\"Scratch OUT_PREFIX:\", OUT_PREFIX)\n",
    "\n",
    "# Create model object\n",
    "m = SfincsModel(root=str(workdir), mode=\"w\")\n",
    "print(\"✅ SfincsModel initialized\")\n",
    "\n",
    "# Safe debug prints across versions\n",
    "print(\"m.root:\", getattr(m, \"root\", None))\n",
    "print(\"Has m.geoms? \", hasattr(m, \"geoms\"))\n",
    "print(\"Has m.grid?  \", hasattr(m, \"grid\"))\n",
    "print(\"Has m.config?\", hasattr(m, \"config\"))\n",
    "\n",
    "# Optional: show available attributes (useful when APIs differ)\n",
    "# print([a for a in dir(m) if \"setup_\" in a])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f6fd1c64-3b8e-4455-80df-5cffcc529042",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Replacing geom: region\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ DEM loaded OK\n",
      "DEM dims: ('y', 'x') | shape: (131, 137)\n",
      "DEM CRS : EPSG:26918\n",
      "DEM res : 25.0\n",
      "DEM bounds: [594250.0, 4517925.0, 597675.0, 4521200.0]\n",
      "\n",
      "Region polygon bounds: [ 594250. 4517925.  597675. 4521200.]\n",
      "\n",
      "setup_region signature: (region: dict, hydrography_fn: str = 'merit_hydro', basin_index_fn: str = 'merit_hydro_index') -> dict\n",
      "setup_grid_from_region signature: (region: 'dict', res: 'float' = 100, crs: 'Union[str, int]' = 'utm', rotated: 'bool' = False, hydrography_fn: 'str' = None, basin_index_fn: 'str' = None, align: 'bool' = False, dec_origin: 'int' = 0, dec_rotation: 'int' = 3)\n",
      "\n",
      "✅ setup_region done\n",
      "Stored region bounds: [ 594250. 4517925.  597675. 4521200.]\n",
      "\n",
      "--- Attempting setup_grid_from_region(...) ---\n",
      "✅ setup_grid_from_region completed (no exception).\n",
      "\n",
      "--- m.grid AFTER setup_grid_from_region ---\n",
      "<xarray.Dataset> Size: 0B\n",
      "Dimensions:  ()\n",
      "Data variables:\n",
      "    *empty*\n",
      "Grid dims: []\n",
      "Grid sizes: {}\n",
      "\n",
      "⚠️ m.grid is empty -> applying FORCE fallback grid based on DEM coordinates\n",
      "\n",
      "✅ Forced fallback grid stored into m._grid\n",
      "m.grid dims now: ['x', 'y']\n",
      "m.grid sizes now: {'x': 137, 'y': 131}\n",
      "\n",
      "✅ Grid raster accessor available\n",
      "Grid CRS   : PROJCS[\"NAD83 / UTM zone 18N\",GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4269\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-75],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"26918\"]]\n",
      "Grid res   : (np.float64(25.0), np.float64(-25.0))\n",
      "Grid bounds: (594250.0, 4517925.0, 597675.0, 4521200.0)\n",
      "\n",
      "✅ Cell 4 finished successfully.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 4) Initialize SFINCS region + grid (ULTRA ROBUST)\n",
    "#    ✅ setup_region from DEM bbox\n",
    "#    ✅ try setup_grid_from_region\n",
    "#    ✅ if m.grid stays empty -> FORCE fallback using DEM coords via m._grid\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import inspect\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 0) Load DEM if missing\n",
    "# ------------------------------------------------------------\n",
    "if \"dem\" not in globals() or dem is None:\n",
    "    if \"paths_local\" not in globals() or \"dep_dem\" not in paths_local:\n",
    "        raise RuntimeError(\"❌ dem not loaded and paths_local['dep_dem'] missing.\")\n",
    "    dem_fn = str(paths_local[\"dep_dem\"])\n",
    "    print(\"✅ Loading DEM:\", dem_fn)\n",
    "    dem = rioxarray.open_rasterio(dem_fn).squeeze()\n",
    "\n",
    "if dem.rio.crs is None:\n",
    "    raise RuntimeError(\"❌ DEM has no CRS. Expected EPSG:26918.\")\n",
    "\n",
    "crs = dem.rio.crs\n",
    "res_x, res_y = dem.rio.resolution()\n",
    "res = float(abs(res_x))\n",
    "\n",
    "minx, miny, maxx, maxy = map(float, dem.rio.bounds())\n",
    "\n",
    "print(\"\\n✅ DEM loaded OK\")\n",
    "print(\"DEM dims:\", dem.dims, \"| shape:\", dem.shape)\n",
    "print(\"DEM CRS :\", crs)\n",
    "print(\"DEM res :\", res)\n",
    "print(\"DEM bounds:\", [minx, miny, maxx, maxy])\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) Create region geom from DEM bbox\n",
    "# ------------------------------------------------------------\n",
    "region_poly = box(minx, miny, maxx, maxy)\n",
    "region_gdf = gpd.GeoDataFrame({\"name\": [\"soundview_bbox\"]}, geometry=[region_poly], crs=crs)\n",
    "\n",
    "print(\"\\nRegion polygon bounds:\", region_gdf.total_bounds)\n",
    "assert np.isfinite(region_gdf.total_bounds).all(), \"❌ Region bounds non-finite.\"\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) Setup region (required)\n",
    "# ------------------------------------------------------------\n",
    "if \"m\" not in globals() or m is None:\n",
    "    raise RuntimeError(\"❌ Model object `m` not defined. Run init cell first.\")\n",
    "\n",
    "print(\"\\nsetup_region signature:\", inspect.signature(m.setup_region))\n",
    "print(\"setup_grid_from_region signature:\", inspect.signature(m.setup_grid_from_region))\n",
    "\n",
    "m.setup_region(region={\"geom\": region_gdf})\n",
    "print(\"\\n✅ setup_region done\")\n",
    "print(\"Stored region bounds:\", m.geoms[\"region\"].total_bounds)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) Try normal HydroMT grid creation\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\n--- Attempting setup_grid_from_region(...) ---\")\n",
    "try:\n",
    "    m.setup_grid_from_region(\n",
    "        region={\"geom\": region_gdf},\n",
    "        res=res,\n",
    "        crs=str(crs),   # EPSG:26918\n",
    "        align=True,\n",
    "    )\n",
    "    print(\"✅ setup_grid_from_region completed (no exception).\")\n",
    "except Exception as e:\n",
    "    print(\"⚠️ setup_grid_from_region raised:\", type(e).__name__, \"-\", e)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4) Check if grid exists; if empty -> FORCE fallback grid from DEM coords\n",
    "# ------------------------------------------------------------\n",
    "grid = m.grid\n",
    "print(\"\\n--- m.grid AFTER setup_grid_from_region ---\")\n",
    "print(grid)\n",
    "print(\"Grid dims:\", list(grid.dims))\n",
    "print(\"Grid sizes:\", dict(grid.sizes))\n",
    "\n",
    "if len(grid.dims) == 0:\n",
    "    print(\"\\n⚠️ m.grid is empty -> applying FORCE fallback grid based on DEM coordinates\")\n",
    "\n",
    "    # DEM coords must be 1D x/y\n",
    "    x = dem[\"x\"].values.astype(\"float64\")\n",
    "    y = dem[\"y\"].values.astype(\"float64\")\n",
    "    if x.ndim != 1 or y.ndim != 1:\n",
    "        raise RuntimeError(\"❌ DEM x/y coords not 1D; cannot force grid fallback.\")\n",
    "\n",
    "    grid_fallback = xr.Dataset(coords={\"x\": (\"x\", x), \"y\": (\"y\", y)})\n",
    "\n",
    "    # Attach CRS + spatial dims via rioxarray (this provides .rio)\n",
    "    grid_fallback = grid_fallback.rio.write_crs(crs)\n",
    "    grid_fallback = grid_fallback.rio.set_spatial_dims(x_dim=\"x\", y_dim=\"y\")\n",
    "\n",
    "    # Many HydroMT models store grid internally as _grid (private)\n",
    "    # This works when m.grid is read-only.\n",
    "    setattr(m, \"_grid\", grid_fallback)\n",
    "\n",
    "    # Re-read m.grid\n",
    "    grid = m.grid\n",
    "    print(\"\\n✅ Forced fallback grid stored into m._grid\")\n",
    "    print(\"m.grid dims now:\", list(grid.dims))\n",
    "    print(\"m.grid sizes now:\", dict(grid.sizes))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5) Final grid validation\n",
    "# ------------------------------------------------------------\n",
    "grid = m.grid\n",
    "\n",
    "# Some versions expose raster accessor via .raster only if it detects x/y dims\n",
    "try:\n",
    "    grid.raster.set_spatial_dims(x_dim=\"x\", y_dim=\"y\")\n",
    "    print(\"\\n✅ Grid raster accessor available\")\n",
    "    print(\"Grid CRS   :\", grid.raster.crs)\n",
    "    print(\"Grid res   :\", grid.raster.res)\n",
    "    print(\"Grid bounds:\", grid.raster.bounds)\n",
    "except Exception as e:\n",
    "    print(\"\\n⚠️ grid.raster accessor not available in this version:\", type(e).__name__, \"-\", e)\n",
    "    print(\"We will continue; setup_dep/mask often still works using x/y coords.\")\n",
    "\n",
    "print(\"\\n✅ Cell 4 finished successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "438cda7d-6994-4c82-8ec8-278194f23a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DEM: /tmp/sfincs_run_inputs_7ad7mvm6/dep_dem_utm25m_meters.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unknown key name in datasets_dep. Ignoring.\n",
      "Interpolate elevation at 506 cells\n",
      "Replacing geom: region\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ dep written to model maps.\n",
      "Maps now include: []\n",
      "✅ Active mask created from bbox geometry.\n",
      "Mask shape: (131, 137)\n",
      "Mask unique values: [1]\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 5) Setup dep + ACTIVE mask (FIXED)\n",
    "#    ✅ setup_mask_active must NOT use mask=\"dep\" in your version\n",
    "#    ✅ Instead, activate the whole bbox region geometry\n",
    "# ============================================================\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "import numpy as np\n",
    "\n",
    "dep_path = str(paths_local[\"dep_dem\"])\n",
    "print(\"Using DEM:\", dep_path)\n",
    "\n",
    "# ---- 1) Setup dep (topobathy) ----\n",
    "datasets_dep = [{\"elevtn\": dep_path, \"name\": \"dem_meters\"}]\n",
    "\n",
    "m.setup_dep(\n",
    "    datasets_dep=datasets_dep,\n",
    "    interp_method=\"linear\",\n",
    ")\n",
    "\n",
    "print(\"✅ dep written to model maps.\")\n",
    "print(\"Maps now include:\", list(m.maps.keys()))\n",
    "\n",
    "# ---- 2) Build an ACTIVE MASK from bbox geometry (robust + simple) ----\n",
    "# Use DEM bounds (same CRS as model)\n",
    "minx, miny, maxx, maxy = map(float, dem.rio.bounds())\n",
    "bbox_poly = box(minx, miny, maxx, maxy)\n",
    "bbox_gdf = gpd.GeoDataFrame({\"name\": [\"active_bbox\"]}, geometry=[bbox_poly], crs=dem.rio.crs)\n",
    "\n",
    "assert np.isfinite(bbox_gdf.total_bounds).all(), \"bbox bounds invalid\"\n",
    "\n",
    "# IMPORTANT: pass a GeoDataFrame (NOT a string like 'dep')\n",
    "m.setup_mask_active(mask=bbox_gdf, reset_mask=True)\n",
    "\n",
    "print(\"✅ Active mask created from bbox geometry.\")\n",
    "print(\"Mask shape:\", m.mask.shape if hasattr(m, \"mask\") else \"unknown\")\n",
    "\n",
    "# Quick sanity check\n",
    "if hasattr(m, \"mask\"):\n",
    "    print(\"Mask unique values:\", np.unique(m.mask.values))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e4b767a4-f14b-47f8-8e22-9023358ca044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Manning raster: /tmp/sfincs_run_inputs_7ad7mvm6/manning_n_utm25m.tif\n",
      "✅ Manning roughness setup done.\n",
      "Maps now contain: []\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 6) Setup Manning roughness (friction)\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "\n",
    "MANNING_NODATA = -9999.0\n",
    "\n",
    "manning_fn = str(paths_local[\"manning\"])\n",
    "print(\"Using Manning raster:\", manning_fn)\n",
    "\n",
    "# hydromt_sfincs expects datasets_rgh as list of dicts with \"manning\"\n",
    "datasets_rgh = [{\"manning\": manning_fn}]\n",
    "\n",
    "m.setup_manning_roughness(\n",
    "    datasets_rgh=datasets_rgh\n",
    ")\n",
    "\n",
    "print(\"✅ Manning roughness setup done.\")\n",
    "print(\"Maps now contain:\", list(m.maps.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e09aa46a-0561-4b12-ba86-6f5723f7eb79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Curve Number raster: /tmp/sfincs_run_inputs_7ad7mvm6/curve_number_cn_utm25m.tif\n",
      "CN dtype: float32 | shape: (131, 137)\n",
      "CN CRS: EPSG:26918 | nodata: -9999.0\n",
      "setup_cn_infiltration signature: (cn, antecedent_moisture='avg', reproj_method='med')\n",
      "✅ CN infiltration setup done.\n",
      "\n",
      "Maps now contain: []\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 7) Setup infiltration from Curve Number raster (CN -> scsfile)\n",
    "#    ✅ Robust to hydromt_sfincs version differences\n",
    "# ============================================================\n",
    "\n",
    "import inspect\n",
    "import numpy as np\n",
    "import rioxarray\n",
    "\n",
    "CN_NODATA = -9999.0  # your convention\n",
    "cn_fn = str(paths_local[\"curve_number\"])\n",
    "\n",
    "print(\"Using Curve Number raster:\", cn_fn)\n",
    "\n",
    "# --- Quick sanity check: file can be opened + has CRS ---\n",
    "cn_da = rioxarray.open_rasterio(cn_fn, masked=False).squeeze()\n",
    "print(\"CN dtype:\", cn_da.dtype, \"| shape:\", cn_da.shape)\n",
    "print(\"CN CRS:\", cn_da.rio.crs, \"| nodata:\", cn_da.rio.nodata)\n",
    "\n",
    "# --- Check method signature for your installed hydromt_sfincs ---\n",
    "sig = inspect.signature(m.setup_cn_infiltration)\n",
    "print(\"setup_cn_infiltration signature:\", sig)\n",
    "\n",
    "# --- Call correctly depending on version ---\n",
    "kwargs = {}\n",
    "\n",
    "# Some versions accept cn as keyword\n",
    "if \"cn\" in sig.parameters:\n",
    "    kwargs[\"cn\"] = cn_fn\n",
    "else:\n",
    "    # Fallback: pass as positional argument\n",
    "    kwargs = None\n",
    "\n",
    "try:\n",
    "    if kwargs is None:\n",
    "        m.setup_cn_infiltration(cn_fn)\n",
    "    else:\n",
    "        m.setup_cn_infiltration(**kwargs)\n",
    "\n",
    "    print(\"✅ CN infiltration setup done.\")\n",
    "except Exception as e:\n",
    "    print(\"❌ setup_cn_infiltration failed:\", repr(e))\n",
    "    print(\"\\nTrying fallback: constant infiltration (disable CN)…\")\n",
    "\n",
    "    # Optional fallback if CN method is incompatible\n",
    "    # This is a *backup* path so your model can still run:\n",
    "    # - user can set a uniform qinf (m/s) if needed\n",
    "    # Example: 5 mm/hr ≈ 1.3889e-6 m/s\n",
    "    qinf_ms = 1.3889e-6\n",
    "    print(f\"⚠️ Using fallback constant infiltration: qinf={qinf_ms:.3e} m/s\")\n",
    "\n",
    "    sig2 = inspect.signature(m.setup_constant_infiltration)\n",
    "    print(\"setup_constant_infiltration signature:\", sig2)\n",
    "\n",
    "    if \"qinf\" in sig2.parameters:\n",
    "        m.setup_constant_infiltration(qinf=qinf_ms)\n",
    "    else:\n",
    "        m.setup_constant_infiltration(qinf_ms)\n",
    "\n",
    "    print(\"✅ Constant infiltration setup done instead.\")\n",
    "\n",
    "# --- Report maps now available ---\n",
    "print(\"\\nMaps now contain:\", list(m.maps.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e99eca82-c393-4938-87aa-909c19d415ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using precip forcing file (TEXT): /tmp/sfincs_run_inputs_70kzhis5/sfincs_precip\n",
      "Exists ✅ | size bytes: 197868\n",
      "Parsed precip format: 2-column precipfile (time + precip)\n",
      "Rows: 8038\n",
      "Precip min/max: 0.0 28.504\n",
      "Time parsed as numeric ✅\n",
      "time min/max: 0 28940400\n",
      "✅ dt (first unique values): [3600 7200]\n",
      "\n",
      "--- First 5 lines (parsed) ---\n",
      "      time  precip\n",
      "0      0.0   0.000\n",
      "1   3600.0   0.017\n",
      "2   7200.0   0.170\n",
      "3  10800.0   8.092\n",
      "4  14400.0   0.781\n",
      "\n",
      "✅ Precip forcing validated as spatially-uniform SFINCS precipfile text.\n",
      "✅ Use this path later as precip_txt_local = /tmp/sfincs_run_inputs_70kzhis5/sfincs_precip\n",
      "Using precip CSV: /tmp/sfincs_run_inputs_7ad7mvm6/sfincs_precip\n",
      "\n",
      "--- Precip CSV preview ---\n",
      "   time_raw   rain\n",
      "0       0.0  0.000\n",
      "1    3600.0  0.017\n",
      "2    7200.0  0.170\n",
      "3   10800.0  8.092\n",
      "4   14400.0  0.781\n",
      "        time_raw  rain\n",
      "8033  28926000.0   0.0\n",
      "8034  28929600.0   0.0\n",
      "8035  28933200.0   0.0\n",
      "8036  28936800.0   0.0\n",
      "8037  28940400.0   0.0\n",
      "\n",
      "Raw time dtype: float64\n",
      "\n",
      "Median delta between time rows: 3600.0\n",
      "✅ Interpreting precip time as minutes since 2025-01-01 00:00:00\n",
      "\n",
      "✅ Parsed precip datetime range:\n",
      "start: 2025-01-01 00:00:00\n",
      "end  : 2080-01-10 12:00:00\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 8) Locate + Validate precipitation forcing (SPATIALLY UNIFORM)\n",
    "#    We use SFINCS \"precipfile\" text format directly (NOT NetCDF)\n",
    "#\n",
    "# Expected format (Deltares SFINCS precipfile):\n",
    "#   - whitespace separated\n",
    "#   - either:\n",
    "#       (A) 2 columns:  <time> <precip>\n",
    "#       (B) 1 column :  <precip>  (implicit timestep index)\n",
    "#\n",
    "# This cell finds the file, validates it, and sets:\n",
    "#   precip_txt_local = \"/path/to/sfincs.precip\"\n",
    "# ============================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 0) Find precip file robustly\n",
    "# ------------------------------------------------------------\n",
    "precip_txt_local = globals().get(\"precip_txt_local\", None)\n",
    "\n",
    "# A) if already specified manually elsewhere\n",
    "if precip_txt_local is not None:\n",
    "    precip_txt_local = str(precip_txt_local)\n",
    "\n",
    "# B) try dictionary keys\n",
    "if precip_txt_local is None and \"paths_local\" in globals() and isinstance(paths_local, dict):\n",
    "    for k in [\"precip\", \"rain\", \"rainfall\", \"sfincs_precip\", \"sfincs.precip\", \"precip_txt\"]:\n",
    "        if k in paths_local:\n",
    "            precip_txt_local = str(paths_local[k])\n",
    "            print(f\"✅ Found precip file from paths_local['{k}'] -> {precip_txt_local}\")\n",
    "            break\n",
    "\n",
    "# C) try autodetect inside cache_dir\n",
    "if precip_txt_local is None:\n",
    "    cache_dir = globals().get(\"cache_dir\", None)\n",
    "    if cache_dir is not None:\n",
    "        cache_dir = Path(cache_dir)\n",
    "        print(\"Searching cache_dir:\", cache_dir)\n",
    "\n",
    "        candidates = []\n",
    "        # prefer classic precipfile names\n",
    "        candidates += list(cache_dir.glob(\"sfincs.precip\"))\n",
    "        candidates += list(cache_dir.glob(\"*sfincs*precip*\"))\n",
    "        candidates += list(cache_dir.glob(\"*precip*\"))\n",
    "        candidates += list(cache_dir.glob(\"*rain*\"))\n",
    "        # also allow csv/txt/dat extensions\n",
    "        candidates += list(cache_dir.glob(\"*.csv\"))\n",
    "        candidates += list(cache_dir.glob(\"*.txt\"))\n",
    "        candidates += list(cache_dir.glob(\"*.dat\"))\n",
    "\n",
    "        # keep only files\n",
    "        candidates = [p for p in candidates if p.exists() and p.is_file()]\n",
    "\n",
    "        # score: prefer exact \"sfincs.precip\", then names containing \"precip\"\n",
    "        def score(p: Path):\n",
    "            n = p.name.lower()\n",
    "            return (\n",
    "                0 if n == \"sfincs.precip\" else 1,\n",
    "                0 if \"precip\" in n else 2,\n",
    "                0 if \"rain\" in n else 3,\n",
    "                len(n),\n",
    "            )\n",
    "\n",
    "        candidates = sorted(set(candidates), key=score)\n",
    "\n",
    "        if len(candidates) > 0:\n",
    "            precip_txt_local = str(candidates[0])\n",
    "            print(\"✅ Auto-detected precip candidate:\", precip_txt_local)\n",
    "            if len(candidates) > 1:\n",
    "                print(\"Other candidates (top 5):\")\n",
    "                for c in candidates[1:6]:\n",
    "                    print(\" -\", c)\n",
    "        else:\n",
    "            raise FileNotFoundError(\n",
    "                \"❌ Could not auto-detect any precip text/CSV file in cache_dir.\\n\"\n",
    "                \"Fix: set precip_txt_local manually.\"\n",
    "            )\n",
    "\n",
    "if precip_txt_local is None:\n",
    "    raise FileNotFoundError(\n",
    "        \"❌ Precip file not found.\\n\"\n",
    "        \"Fix: set precip_txt_local = '/path/to/sfincs.precip'\"\n",
    "    )\n",
    "\n",
    "precip_txt_local = Path(precip_txt_local)\n",
    "print(\"\\nUsing precip forcing file (TEXT):\", precip_txt_local)\n",
    "\n",
    "if not precip_txt_local.exists():\n",
    "    raise FileNotFoundError(f\"❌ Missing precip file: {precip_txt_local}\")\n",
    "\n",
    "print(\"Exists ✅ | size bytes:\", precip_txt_local.stat().st_size)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) Quick binary/text sanity check (must be text)\n",
    "# ------------------------------------------------------------\n",
    "with open(precip_txt_local, \"rb\") as f:\n",
    "    head = f.read(64)\n",
    "\n",
    "# if it looks like NetCDF/HDF, reject (you said no NetCDF)\n",
    "if head[:3] == b\"CDF\" or head.startswith(b\"\\x89HDF\\r\\n\\x1a\\n\"):\n",
    "    raise RuntimeError(\n",
    "        \"❌ This precip file is actually a NetCDF/HDF binary file.\\n\"\n",
    "        f\"Path: {precip_txt_local}\\n\"\n",
    "        \"But we expect a TEXT precipfile (sfincs.precip).\"\n",
    "    )\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) Parse as whitespace table (1 or 2 columns)\n",
    "# ------------------------------------------------------------\n",
    "df = pd.read_csv(\n",
    "    precip_txt_local,\n",
    "    sep=r\"\\s+\",\n",
    "    header=None,\n",
    "    engine=\"python\",\n",
    "    comment=\"#\",\n",
    ")\n",
    "\n",
    "if df.shape[1] == 0:\n",
    "    raise RuntimeError(\"❌ Precip file parsed to 0 columns. File is empty or invalid.\")\n",
    "\n",
    "if df.shape[1] == 1:\n",
    "    df.columns = [\"precip\"]\n",
    "    df[\"time\"] = np.arange(len(df), dtype=\"int64\")\n",
    "    df = df[[\"time\", \"precip\"]]\n",
    "    fmt = \"1-column precipfile (implicit timestep index)\"\n",
    "elif df.shape[1] >= 2:\n",
    "    df = df.iloc[:, :2].copy()\n",
    "    df.columns = [\"time\", \"precip\"]\n",
    "    fmt = \"2-column precipfile (time + precip)\"\n",
    "else:\n",
    "    raise RuntimeError(\"❌ Unexpected precip table shape.\")\n",
    "\n",
    "print(\"Parsed precip format:\", fmt)\n",
    "print(\"Rows:\", len(df))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) Validate numeric precip\n",
    "# ------------------------------------------------------------\n",
    "df[\"precip\"] = pd.to_numeric(df[\"precip\"], errors=\"coerce\")\n",
    "n_bad = int(df[\"precip\"].isna().sum())\n",
    "if n_bad > 0:\n",
    "    raise RuntimeError(f\"❌ Precip column has {n_bad} NaNs (non-numeric values).\")\n",
    "\n",
    "pmin = float(df[\"precip\"].min())\n",
    "pmax = float(df[\"precip\"].max())\n",
    "print(\"Precip min/max:\", pmin, pmax)\n",
    "\n",
    "if pmax < 0:\n",
    "    raise RuntimeError(\"❌ Precipitation is negative everywhere. Probably wrong units/sign.\")\n",
    "\n",
    "# optional: warn if huge values\n",
    "if pmax > 500:\n",
    "    print(\"⚠️ Warning: very large precip values (>500). Check units (mm/hr vs mm/day).\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4) Validate time column (numeric or datetime-like string)\n",
    "# ------------------------------------------------------------\n",
    "tcol = df[\"time\"].iloc[:10].astype(str).tolist()\n",
    "\n",
    "# attempt datetime parse if it looks like datetime strings\n",
    "looks_datetime = any((\"-\" in s or \"T\" in s or \":\" in s) for s in tcol)\n",
    "\n",
    "if looks_datetime:\n",
    "    t = pd.to_datetime(df[\"time\"], errors=\"coerce\")\n",
    "    if t.isna().any():\n",
    "        raise RuntimeError(\"❌ time column looked datetime-like but datetime parsing failed.\")\n",
    "    print(\"Time parsed as datetime ✅\")\n",
    "    print(\"time start:\", t.iloc[0])\n",
    "    print(\"time end  :\", t.iloc[-1])\n",
    "else:\n",
    "    # numeric time\n",
    "    tnum = pd.to_numeric(df[\"time\"], errors=\"coerce\")\n",
    "    if tnum.isna().any():\n",
    "        raise RuntimeError(\"❌ time column is neither valid datetime nor numeric.\")\n",
    "    tnum = tnum.astype(\"int64\").values\n",
    "    print(\"Time parsed as numeric ✅\")\n",
    "    print(\"time min/max:\", int(tnum.min()), int(tnum.max()))\n",
    "\n",
    "    if len(tnum) >= 2:\n",
    "        dt = np.unique(np.diff(tnum[:min(len(tnum), 1000)]))\n",
    "        if len(dt) > 10:\n",
    "            print(\"⚠️ time step looks irregular (many dt values):\", dt[:10])\n",
    "        else:\n",
    "            print(\"✅ dt (first unique values):\", dt[:10])\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5) Print preview\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\n--- First 5 lines (parsed) ---\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\n✅ Precip forcing validated as spatially-uniform SFINCS precipfile text.\")\n",
    "print(\"✅ Use this path later as precip_txt_local =\", str(precip_txt_local))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 8b) Fix precip CSV time axis (convert numeric -> datetime in 2025)\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "precip_local = globals().get(\"precip_local\", None)\n",
    "if precip_local is None:\n",
    "    raise RuntimeError(\"❌ precip_local not set. Run Cell 8 first.\")\n",
    "\n",
    "print(\"Using precip CSV:\", precip_local)\n",
    "\n",
    "dfp = pd.read_csv(\n",
    "    precip_local,\n",
    "    sep=r\"\\s+\",\n",
    "    header=None,\n",
    "    names=[\"time_raw\", \"rain\"],\n",
    ")\n",
    "\n",
    "print(\"\\n--- Precip CSV preview ---\")\n",
    "print(dfp.head())\n",
    "print(dfp.tail())\n",
    "print(\"\\nRaw time dtype:\", dfp[\"time_raw\"].dtype)\n",
    "\n",
    "# ---- Case A: time is already ISO-like strings\n",
    "if dfp[\"time_raw\"].dtype == object:\n",
    "    t = pd.to_datetime(dfp[\"time_raw\"], errors=\"raise\")\n",
    "    dfp[\"time\"] = t\n",
    "\n",
    "# ---- Case B: time is numeric (likely minutes since start)\n",
    "else:\n",
    "    tnum = dfp[\"time_raw\"].to_numpy()\n",
    "\n",
    "    # Heuristic: interpret as minutes since simulation start\n",
    "    # This is consistent with your FEWS wind convention, and typical SFINCS forcing.\n",
    "    # If your teammate used seconds instead of minutes, we detect it below.\n",
    "    dt_guess_minutes = np.median(np.diff(tnum[:min(len(tnum), 1000)]))\n",
    "    print(\"\\nMedian delta between time rows:\", dt_guess_minutes)\n",
    "\n",
    "    # Detect seconds vs minutes\n",
    "    # if timestep is ~60 -> seconds\n",
    "    # if timestep is ~1  -> minutes (hourly data would be 60 minutes)\n",
    "    if 50 <= dt_guess_minutes <= 70:\n",
    "        units = \"seconds\"\n",
    "        base = pd.Timestamp(\"2025-01-01 00:00:00\")\n",
    "        dfp[\"time\"] = base + pd.to_timedelta(tnum, unit=\"s\")\n",
    "    else:\n",
    "        units = \"minutes\"\n",
    "        base = pd.Timestamp(\"2025-01-01 00:00:00\")\n",
    "        dfp[\"time\"] = base + pd.to_timedelta(tnum, unit=\"m\")\n",
    "\n",
    "    print(\"✅ Interpreting precip time as\", units, \"since\", base)\n",
    "\n",
    "print(\"\\n✅ Parsed precip datetime range:\")\n",
    "print(\"start:\", dfp[\"time\"].iloc[0])\n",
    "print(\"end  :\", dfp[\"time\"].iloc[-1])\n",
    "\n",
    "# Save back into globals for downstream cells\n",
    "precip_df = dfp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6d48be7a-1ee3-443c-92d4-54a0e8c5eb79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using wind forcing file: /tmp/sfincs_run_inputs_7ad7mvm6/netamuamvfile.nc\n",
      "Using precip forcing file: /tmp/sfincs_run_inputs_7ad7mvm6/sfincs_precip\n",
      "\n",
      "--- Wind dataset (after rename) ---\n",
      "<xarray.Dataset> Size: 187kB\n",
      "Dimensions:   (time: 7800, y: 1, x: 2)\n",
      "Coordinates:\n",
      "  * time      (time) datetime64[ns] 62kB 2025-01-01 ... 2025-11-21T23:00:00\n",
      "  * y         (y) float64 8B 4.52e+06\n",
      "  * x         (x) float64 16B 5.946e+05 5.975e+05\n",
      "Data variables:\n",
      "    wind10_u  (time, y, x) float32 62kB -3.468 -3.156 -3.49 ... 2.049 1.986\n",
      "    wind10_v  (time, y, x) float32 62kB -2.423 -2.798 -2.997 ... 0.9387 1.001\n",
      "Attributes:\n",
      "    crs:      EPSG:26918\n",
      "\n",
      "✅ Wind CRS via raster: EPSG:26918\n",
      "\n",
      "✅ Precip time range: 1970-01-01T00:00:00.000000000 -> 1970-01-01T00:00:00.028940400\n",
      "\n",
      "✅ Wind time range: 2025-01-01T00:00:00.000000000 -> 2025-11-21T23:00:00.000000000\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "❌ NO TIME OVERLAP between precip CSV and wind NetCDF.\n\nPrecip: 1970-01-01T00:00:00.000000000 -> 1970-01-01T00:00:00.028940400\nWind  : 2025-01-01T00:00:00.000000000 -> 2025-11-21T23:00:00.000000000\n\nFix: regenerate the wind forcing for the same year as precipitation (or regenerate precipitation for the wind year).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[61]\u001b[39m\u001b[32m, line 121\u001b[39m\n\u001b[32m    118\u001b[39m t1 = \u001b[38;5;28mmin\u001b[39m(t_precip1, t_w1)\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m t1 < t0:\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    122\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m❌ NO TIME OVERLAP between precip CSV and wind NetCDF.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    123\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPrecip: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_precip0\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m -> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_precip1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    124\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mWind  : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_w0\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m -> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_w1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    125\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFix: regenerate the wind forcing for the same year as precipitation \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    126\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m(or regenerate precipitation for the wind year).\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    127\u001b[39m     )\n\u001b[32m    129\u001b[39m ds_w = ds_w.sel(time=\u001b[38;5;28mslice\u001b[39m(t0, t1))\n\u001b[32m    130\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m✅ Sliced wind to overlap window:\u001b[39m\u001b[33m\"\u001b[39m, ds_w.time.values[\u001b[32m0\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33m->\u001b[39m\u001b[33m\"\u001b[39m, ds_w.time.values[-\u001b[32m1\u001b[39m])\n",
      "\u001b[31mRuntimeError\u001b[39m: ❌ NO TIME OVERLAP between precip CSV and wind NetCDF.\n\nPrecip: 1970-01-01T00:00:00.000000000 -> 1970-01-01T00:00:00.028940400\nWind  : 2025-01-01T00:00:00.000000000 -> 2025-11-21T23:00:00.000000000\n\nFix: regenerate the wind forcing for the same year as precipitation (or regenerate precipitation for the wind year)."
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 9) Attach wind forcing (ROBUST: time-overlap safe + rename + CRS)\n",
    "# ============================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "# ------------------------------\n",
    "# 0) paths\n",
    "# ------------------------------\n",
    "wind_local = globals().get(\"wind_local\", \"/tmp/sfincs_run_inputs_1mk6ynd6/netamuamvfile.nc\")\n",
    "precip_local = globals().get(\"precip_local\", None)  # should exist from Cell 8\n",
    "\n",
    "print(\"Using wind forcing file:\", wind_local)\n",
    "if precip_local is not None:\n",
    "    print(\"Using precip forcing file:\", precip_local)\n",
    "else:\n",
    "    print(\"⚠️ precip_local not found in globals(); will attach wind without time slicing (may fail).\")\n",
    "\n",
    "if not Path(wind_local).exists():\n",
    "    raise FileNotFoundError(f\"❌ Wind file not found: {wind_local}\")\n",
    "\n",
    "# ------------------------------\n",
    "# 1) open wind file + rename\n",
    "# ------------------------------\n",
    "ds_w = xr.open_dataset(wind_local, engine=\"netcdf4\")\n",
    "\n",
    "rename_map = {}\n",
    "if \"amu\" in ds_w:\n",
    "    rename_map[\"amu\"] = \"wind10_u\"\n",
    "if \"amv\" in ds_w:\n",
    "    rename_map[\"amv\"] = \"wind10_v\"\n",
    "\n",
    "ds_w = ds_w.rename(rename_map)\n",
    "\n",
    "if \"wind10_u\" not in ds_w or \"wind10_v\" not in ds_w:\n",
    "    raise RuntimeError(\n",
    "        \"❌ Wind dataset must contain wind10_u and wind10_v.\\n\"\n",
    "        f\"Vars found: {list(ds_w.data_vars)}\"\n",
    "    )\n",
    "\n",
    "# ensure dims\n",
    "needed = {\"time\", \"y\", \"x\"}\n",
    "if not needed.issubset(ds_w.dims):\n",
    "    raise RuntimeError(f\"❌ Wind dims must include {needed}, got {dict(ds_w.sizes)}\")\n",
    "\n",
    "# float32\n",
    "ds_w[\"wind10_u\"] = ds_w[\"wind10_u\"].astype(\"float32\")\n",
    "ds_w[\"wind10_v\"] = ds_w[\"wind10_v\"].astype(\"float32\")\n",
    "\n",
    "print(\"\\n--- Wind dataset (after rename) ---\")\n",
    "print(ds_w)\n",
    "\n",
    "# ------------------------------\n",
    "# 2) attach HydroMT raster metadata (IMPORTANT)\n",
    "# ------------------------------\n",
    "# use DEM CRS if available\n",
    "if \"dem\" in globals() and hasattr(dem, \"rio\") and dem.rio.crs is not None:\n",
    "    crs_guess = str(dem.rio.crs)\n",
    "else:\n",
    "    crs_guess = ds_w.attrs.get(\"crs\", \"EPSG:26918\")\n",
    "\n",
    "ds_w.attrs[\"crs\"] = crs_guess\n",
    "\n",
    "# make x/y increasing (helps slicer)\n",
    "if np.any(np.diff(ds_w[\"x\"].values) < 0):\n",
    "    ds_w = ds_w.isel(x=slice(None, None, -1))\n",
    "if np.any(np.diff(ds_w[\"y\"].values) < 0):\n",
    "    ds_w = ds_w.isel(y=slice(None, None, -1))\n",
    "\n",
    "# attach hydromt raster accessor (inplace!)\n",
    "ds_w.raster.set_spatial_dims(x_dim=\"x\", y_dim=\"y\")\n",
    "ds_w.raster.set_crs(crs_guess)\n",
    "\n",
    "print(\"\\n✅ Wind CRS via raster:\", ds_w.raster.crs)\n",
    "\n",
    "# ------------------------------\n",
    "# 3) determine precip time range (CSV uniform rainfall)\n",
    "# ------------------------------\n",
    "t_precip0 = None\n",
    "t_precip1 = None\n",
    "\n",
    "if precip_local is not None and Path(precip_local).exists():\n",
    "    # your precip file is a 2-column space-separated CSV:\n",
    "    # time precipitation\n",
    "    # with no headers\n",
    "    dfp = pd.read_csv(\n",
    "        precip_local,\n",
    "        sep=r\"\\s+\",\n",
    "        header=None,\n",
    "        names=[\"time\", \"rain\"],\n",
    "    )\n",
    "\n",
    "    # Try parsing time column to datetime\n",
    "    # (This works if the first column is ISO time strings like 2020-01-01T00:00:00)\n",
    "    try:\n",
    "        t = pd.to_datetime(dfp[\"time\"])\n",
    "        t_precip0 = np.datetime64(t.iloc[0].to_datetime64())\n",
    "        t_precip1 = np.datetime64(t.iloc[-1].to_datetime64())\n",
    "        print(\"\\n✅ Precip time range:\", t_precip0, \"->\", t_precip1)\n",
    "    except Exception as e:\n",
    "        print(\"\\n⚠️ Could not parse precip time column as datetime.\")\n",
    "        print(\"   Sample first rows:\\n\", dfp.head())\n",
    "        print(\"   Error:\", type(e).__name__, \"-\", e)\n",
    "\n",
    "# ------------------------------\n",
    "# 4) slice wind to precip overlap if possible\n",
    "# ------------------------------\n",
    "t_w0 = ds_w[\"time\"].values[0]\n",
    "t_w1 = ds_w[\"time\"].values[-1]\n",
    "print(\"\\n✅ Wind time range:\", t_w0, \"->\", t_w1)\n",
    "\n",
    "if (t_precip0 is not None) and (t_precip1 is not None):\n",
    "    # overlap window\n",
    "    t0 = max(t_precip0, t_w0)\n",
    "    t1 = min(t_precip1, t_w1)\n",
    "\n",
    "    if t1 < t0:\n",
    "        raise RuntimeError(\n",
    "            \"❌ NO TIME OVERLAP between precip CSV and wind NetCDF.\\n\\n\"\n",
    "            f\"Precip: {t_precip0} -> {t_precip1}\\n\"\n",
    "            f\"Wind  : {t_w0} -> {t_w1}\\n\\n\"\n",
    "            \"Fix: regenerate the wind forcing for the same year as precipitation \"\n",
    "            \"(or regenerate precipitation for the wind year).\"\n",
    "        )\n",
    "\n",
    "    ds_w = ds_w.sel(time=slice(t0, t1))\n",
    "    print(\"\\n✅ Sliced wind to overlap window:\", ds_w.time.values[0], \"->\", ds_w.time.values[-1])\n",
    "else:\n",
    "    print(\"\\n⚠️ Precip time range unknown; skipping wind time slicing.\")\n",
    "\n",
    "# ------------------------------\n",
    "# 5) set model time window (IMPORTANT so HydroMT doesn't slice wind to None)\n",
    "# ------------------------------\n",
    "# try to set start/stop in model config if available\n",
    "if hasattr(m, \"config\") and isinstance(m.config, dict) and ds_w.sizes[\"time\"] > 0:\n",
    "    t0 = pd.to_datetime(ds_w.time.values[0]).strftime(\"%Y%m%d %H%M%S\")\n",
    "    t1 = pd.to_datetime(ds_w.time.values[-1]).strftime(\"%Y%m%d %H%M%S\")\n",
    "\n",
    "    # these are common SFINCS config keys (harmless if unused)\n",
    "    m.config[\"tstart\"] = t0\n",
    "    m.config[\"tstop\"]  = t1\n",
    "    print(\"\\n✅ Set model config time:\")\n",
    "    print(\"   tstart =\", m.config[\"tstart\"])\n",
    "    print(\"   tstop  =\", m.config[\"tstop\"])\n",
    "else:\n",
    "    print(\"\\n⚠️ Could not set model config time (m.config not available).\")\n",
    "\n",
    "# ------------------------------\n",
    "# 6) attach wind forcing\n",
    "# ------------------------------\n",
    "m.setup_wind_forcing_from_grid(wind=ds_w)\n",
    "print(\"\\n✅ Wind forcing attached successfully.\")\n",
    "print(\"Forcing keys now:\", list(getattr(m, \"forcing\", {}).keys()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf92dde-d944-4541-af7e-45af8171c69e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
